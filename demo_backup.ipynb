{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistant API Demo\n",
    "This notebook acts as an introduction into the assistants API and some of the potential use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import find_dotenv,load_dotenv\n",
    "\n",
    "from openai import OpenAI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading enviroment variables \n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a simple chat request \n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of code, where logic converges,\n",
      "A concept arises, both puzzling and emergent,\n",
      "A dance of repetition, elegant and profound,\n",
      "Welcome, dear friend, to the world of recursion!\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content[:184])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping context\n",
    "Now that is quite simple but if we want it to keep context of the chat we have had one thing we need to do is pass more messages in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"},\n",
    "    {\"role\": \"system\", \"content\": \"In the realm of code, where logic converges, A concept arises, both puzzling and emergent,A dance of repetition, elegant and profound,Welcome, dear friend, to the world of recursion!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Okay can you change it to be about encapsulation and do it in under 200 words?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of code, where secrets lie,\n",
      "Lies a concept hidden from mortal eye,\n",
      "A potent spell, a mystical dream,\n",
      "Welcome, dear friends, to encapsulation supreme!\n",
      "\n",
      "It's a fort of data, carefully sealed,\n",
      "Shielded from prying eyes, its truth concealed,\n",
      "Inside the walls, methods whisper and sing,\n",
      "Oblivious to the chaos that the outside may bring.\n",
      "\n",
      "Like ancient scrolls in a cryptic tome,\n",
      "Encapsulation shelters, keeps data at home,\n",
      "It binds them tight, away from harm's spoil,\n",
      "Guarding its essence, within a sacred coil.\n",
      "\n",
      "So cherish this art, this enchanted domain,\n",
      "Where data is sovereign and safeguards remain,\n",
      "For in the embrace of encapsulation pure,\n",
      "Lies the beauty of code, unspoiled and secure.\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nice it understands the task and keeps the same style \n",
    "len(completion.choices[0].message.content.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Assistant API \n",
    "Setting up a little more complex but allows us a lot more to play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Currently, the weather in San Francisco is 72°F, in Tokyo it's 10°C, and in Paris it's 22°C.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "\n",
    "# Step 1: send the conversation and available functions to the model\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    ")\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "# Step 2: check if the model wanted to call a function\n",
    "if tool_calls:\n",
    "    # Step 3: call the function\n",
    "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "    }  # only one function in this example, but you can have multiple\n",
    "    messages.append(response_message)  # extend conversation with assistant's reply\n",
    "    # Step 4: send the info for each function call and function response to the model\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        function_response = function_to_call(\n",
    "            location=function_args.get(\"location\"),\n",
    "            unit=function_args.get(\"unit\"),\n",
    "        )\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "    )  # get a new response from the model where it can see the function response\n",
    "\n",
    "second_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        # We can also use some of the other tools like code interpreters or Dalle \n",
    "        \"type\": \"function\",\n",
    "        # Defining the function itself \n",
    "        \"function\": {\n",
    "            # The name of your function in yoru code base \n",
    "            \"name\": \"get_current_weather\",\n",
    "            # A brief description so the bot knows when to try to call this function \n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            # Defining each parameter for the function \n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                # This allows us to make any of our parameteres required e.g. this won't run if it can't get it \n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very similar to earlier as we can see with the addition of the tools and tool_choice params \n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we had more functions we would add them in here and to the tools \n",
    "available_functions = {\n",
    "    # Important that the text name you give the function matches in tools and here so gpt knows how to build it \n",
    "        \"get_current_weather\": get_current_weather,\n",
    "    }  # only one function in this example, but you can have multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessageToolCall(id='call_ES62QHybGF2SM4leEuHqxkPe', function=Function(arguments='{\"location\": \"San Francisco, CA\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
      "ChatCompletionMessageToolCall(id='call_ZcMMAho458bGArUOqQodUgXf', function=Function(arguments='{\"location\": \"Tokyo, Japan\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
      "ChatCompletionMessageToolCall(id='call_mpcMgJLTCe0uwUvrchw2U0vL', function=Function(arguments='{\"location\": \"Paris, France\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n"
     ]
    }
   ],
   "source": [
    "for tool_call in tool_calls:\n",
    "    print(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Paris, France', 'unit': 'celsius'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets the name of the function you want to run and then the actual function \n",
    "function_name = tool_call.function.name\n",
    "function_to_call = available_functions[function_name]\n",
    "#Retreives the parameteres for the function \n",
    "function_args = json.loads(tool_call.function.arguments)\n",
    "# Calls the function with the approriate params \n",
    "function_response = function_to_call(\n",
    "    location=function_args.get(\"location\"),\n",
    "    unit=function_args.get(\"unit\"),\n",
    ")\n",
    "function_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$191.12'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_current_price(ticker:str):\n",
    "    \"\"\"Given a companies ticker return the current stock price \"\"\"\n",
    "    data = r.get(f'https://financialmodelingprep.com/api/v3/profile/{ticker}?apikey=QJ0BZyAOPg4M4iXiYCMpxTmQ340N5KdU').json()\n",
    "    return \"$\" + str(data[0]['price'])\n",
    "\n",
    "get_current_price('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current stock price for AAPL (Apple Inc.) is $191.2.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_prompt(messages:list):\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_price\",\n",
    "                \"description\": \"Get the current price of a stock\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"ticker\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The ticker of a stock\",\n",
    "                        },\n",
    "                        \n",
    "                    },\n",
    "                    \"required\": [\"ticker\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_price\": get_current_price,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                ticker=function_args.get(\"ticker\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response\n",
    "    \n",
    "messages = [{\"role\": \"user\", \"content\": \"What's is AAPL stock price?\"}]\n",
    "run_prompt(messages).choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different message??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current stock price for Meta (formerly Facebook) is $339.345.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What's is Metas stock price?\"}]\n",
    "run_prompt(messages).choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have the current stock price for Facebook (FB). You can check the latest stock price on a financial news website or by using a stock market app.\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What's is Facebooks stock price?\"}]\n",
    "run_prompt(messages).choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the function \n",
    "What happens if we change the function to something taht returns all the data about the stock?? Will it be able to tell us more or just do a dump with all the extra information we give it??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current stock price for AAPL (Apple Inc.) is $191.26 USD.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_stock_information(ticker:str):\n",
    "    \"\"\"Given a companies ticker return the current stock price \"\"\"\n",
    "    data = r.get(f'https://financialmodelingprep.com/api/v3/profile/{ticker}?apikey=QJ0BZyAOPg4M4iXiYCMpxTmQ340N5KdU').json()\n",
    "    return str(data[0])\n",
    "\n",
    "def run_prompt(messages:list):\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_stock_information\",\n",
    "                \"description\": \"Get a json object of all current information about a stock\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"ticker\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The ticker of a stock\",\n",
    "                        },\n",
    "                        \n",
    "                    },\n",
    "                    \"required\": [\"ticker\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_stock_information\": get_stock_information,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                ticker=function_args.get(\"ticker\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response\n",
    "    \n",
    "messages = [{\"role\": \"user\", \"content\": \"What's is AAPL stock price?\"}]\n",
    "run_prompt(messages).choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting\n",
    "It seems to be able to parse through the information we give it, Lets ask about some of the other attributes it returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can find the image of Apple Inc. on this link: [Apple Inc. Image](https://financialmodelingprep.com/image-stock/AAPL.png)'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What's is link to the image of apples company?\"}]\n",
    "run_prompt(messages).choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Apple Inc. is a multinational technology company that designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers a wide range of products, including the iPhone, Mac, iPad, and various wearables and accessories. In addition to its hardware offerings, Apple also provides various services such as AppleCare support, cloud services, and operates platforms like the App Store and Apple Music. The company serves consumers, small and mid-sized businesses, and the education, enterprise, and government markets. Apple distributes its products through its retail and online stores, as well as through third-party cellular network carriers, wholesalers, retailers, and resellers. The company was incorporated in 1977 and is headquartered in Cupertino, California. Apple's CEO is Mr. Timothy D. Cook, and it has approximately 161,000 full-time employees.\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Can you give me a description of apple?\"}]\n",
    "run_prompt(messages).choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The CEO of Apple is Mr. Timothy D. Cook.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Who is the CEO of apple\"}]\n",
    "run_prompt(messages).choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall\n",
    "Overall I think the assistants API is the future of any development in this field of building business inteligence tools, This allows for rapid development in line with current dev standards!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
